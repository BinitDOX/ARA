{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DEPENDENCIES","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install hyperdb-python\n!pip install sentence-transformers\n!pip install pyngrok\n!pip install exllamav2==0.0.8\n!pip install edge-tts\n!pip install rvc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# IMPORTS","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"from exllamav2 import (ExLlamaV2, ExLlamaV2Config, ExLlamaV2Cache, ExLlamaV2Tokenizer)\nfrom exllamav2.generator import (ExLlamaV2StreamingGenerator, ExLlamaV2Sampler)\nfrom sentence_transformers import SentenceTransformer\nfrom hyperdb import HyperDB\nfrom huggingface_hub import snapshot_download, hf_hub_download\n\nimport edge_tts\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nfrom scipy.io import wavfile\nfrom rvc.modules.vc.modules import VC\n\nimport uvicorn\nimport asyncio\nfrom fastapi import FastAPI, Request\nfrom fastapi.responses import FileResponse\nfrom pydantic import BaseModel, Field\nfrom typing import Any, Optional\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives import padding\nfrom datetime import datetime\nimport base64\nimport json\nimport calendar\nimport time\nimport pytz\nimport threading\nimport os\nimport re\nimport shutil\nimport subprocess\nimport sys\nimport logging\nimport nest_asyncio\nnest_asyncio.apply()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CONSTANTS","metadata":{}},{"cell_type":"code","source":"# NGROK\nNGROK_AUTHTOKEN = \"\"\nNGROK_STATIC_DOMAIN = \"\"\n\n# LLM\nLLM_MODEL_ID = \"TheBloke/dolphin-2.1-mistral-7B-GPTQ\"\nLLM_FOLDER = \"llm\"\nEMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\nMAX_NEW_TOKENS = 256\nLAST_CONTEXT = 11\nLONG_TERM_CONTEXT = 10\nAPPLY_CHAT_TEMPLATE = True\n\n# RVC\nRVC_FOLDER = \"rvc\"\nRVCMD_FOLDER = \"rvcmd\"\nRVC_ASSETS_DOWNLOADER_URL = \"https://github.com/RVC-Project/RVC-Models-Downloader/releases/download/v0.2.4/rvcmd_linux_386.tar.gz\"\n\nRVC_MIKU_MODEL_URL = \"https://huggingface.co/juuxn/RVCModels/resolve/main/miku222333333.zip\"\nRVC_MIKU = \"miku\"\nRVC_MIKU_MODEL_NAME = \"miku222333333.pth\"\n\nRVC_HOSHINO_MODEL_URL = '\"https://huggingface.co/juuxn/RVCModels/resolve/main/Ai_Hoshino_(From_Oshi_no_Ko)_(RVC_v2)_300_Epoch.zip\"'\nRVC_HOSHINO = \"hoshino\"\nRVC_HOSHINO_MODEL_NAME = \"AiHoshino.pth\"\n\nRVC_GLADOS_MODEL_URL = \"https://huggingface.co/juuxn/RVCModels/resolve/main/glados2333333.zip\"\nRVC_GLADOS = \"glados\"\nRVC_GLADOS_MODEL_NAME = \"glados2333333.pth\"\n\n\n# Authentication\nDELIMITER_DATA_DATE = \"<DATA_DATE>\"\nAUTH_KEY_DECRYPTION_KEY = \"B9CF1133E770E069695ZX8E6F4F0B9B5\"\nAUTH_TOKEN_ENCRYPTION_KEY = \"A5DE2143E770E069695ZX8E6FDBB7BBE\"\nENCRYPTION_ALGORITHM = \"AES\"\nAUTH_TOKEN_EXPIRY_DAYS = 7\nCHARACTER_ENCODING = \"utf-8\"\n\n# Assets\nASSISTANTS_FOLDER = \"assistants\"\nDEVICES_FOLDER = \"devices\"\nCONVERSATION_FILE = \"conversation.jsonl\"\nVOICE_CONFIGURATION_FILE = \"voice_configuration.jsonl\"\nHYPER_DB_FILE = \"conversation.pickle.gz\"\nTEMP_FILE = \"temp.jsonl\"\nPROMPT_FILE = \"prompt.txt\"\nEDGE_TTS_FILE = \"edge_tts.wav\"\nRVC_STS_FILE = \"rvc_tts.wav\"\n\n# Application\nAPP_ID = \"ara\"\nDEVICE_ID_KEY = \"DeviceID\"\nAUTHORIZATION_KEY = \"Authorization\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SETUP","metadata":{}},{"cell_type":"code","source":"# Download LLM\nif not os.path.exists(LLM_FOLDER):\n    os.makedirs(LLM_FOLDER, exist_ok=True)\n    snapshot_download(repo_id=LLM_MODEL_ID, local_dir=LLM_FOLDER, local_dir_use_symlinks=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup LLM\nllm_config = ExLlamaV2Config()\nllm_config.model_dir = LLM_FOLDER\nllm_config.prepare()\n\nExLlamatokenizer = ExLlamaV2Tokenizer(llm_config)\nllm_model = ExLlamaV2(llm_config)\nllm_model.load([16, 24])\n\nllm_cache = ExLlamaV2Cache(llm_model)\n\nllm_generator = ExLlamaV2StreamingGenerator(llm_model, llm_cache, ExLlamatokenizer)\nllm_generator.set_stop_conditions(['}'])\n\nllm_settings = ExLlamaV2Sampler.Settings()\nllm_settings.temperature = 0.85\nllm_settings.top_k = 50\nllm_settings.top_p = 0.8\nllm_settings.token_repetition_penalty = 1.15\nllm_settings.disallow_tokens(ExLlamatokenizer, [ExLlamatokenizer.eos_token_id])\n\nllm_max_new_tokens = MAX_NEW_TOKENS","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download RVC Models\n# For more: https://docs.google.com/spreadsheets/d/1owfUtQuLW9ReiIwg6U9UkkDmPOTkuNHf0OKQtWu1iaI\nos.makedirs(RVC_FOLDER, exist_ok=True)\n\n# Download Model-1:\nif not os.path.exists(f\"{RVC_FOLDER}/{RVC_MIKU}\"):\n    !wget {RVC_MIKU_MODEL_URL} -O {RVC_FOLDER}/{RVC_MIKU}.zip\n    !unzip {RVC_FOLDER}/{RVC_MIKU}.zip -d {RVC_FOLDER}/{RVC_MIKU}\n    \n# Download Model-2:\nif not os.path.exists(f\"{RVC_FOLDER}/{RVC_HOSHINO}\"):\n    !wget {RVC_HOSHINO_MODEL_URL} -O {RVC_FOLDER}/{RVC_HOSHINO}.zip\n    !unzip {RVC_FOLDER}/{RVC_HOSHINO}.zip -d {RVC_FOLDER}/{RVC_HOSHINO}\n    \n# Download Model-3:\nif not os.path.exists(f\"{RVC_FOLDER}/{RVC_GLADOS}\"):\n    !wget {RVC_GLADOS_MODEL_URL} -O {RVC_FOLDER}/{RVC_GLADOS}.zip\n    !unzip {RVC_FOLDER}/{RVC_GLADOS}.zip -d {RVC_FOLDER}/{RVC_GLADOS}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download RVC Assets downloader\nif not os.path.exists(f\"{RVC_FOLDER}/{RVCMD_FOLDER}\"):\n    !wget {RVC_ASSETS_DOWNLOADER_URL} -O {RVC_FOLDER}/rvcmd.tar.gz\n    os.makedirs(f'{RVC_FOLDER}/{RVCMD_FOLDER}', exist_ok=True)\n    !tar -xvf {RVC_FOLDER}/rvcmd.tar.gz -C {RVC_FOLDER}/{RVCMD_FOLDER}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cwd = os.getcwd()\nos.chdir(RVC_FOLDER)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download RVC Assets\nif not os.path.exists(\"assets\"):\n    !{RVCMD_FOLDER}/rvcmd assets/all","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.chdir(cwd)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile {RVC_FOLDER}/rvc.env\nweight_root='/kaggle/working/rvc/assets'\nweight_uvr5_root='/kaggle/working/rvc/assets/uvr5_weights'\nindex_root='/kaggle/working/rvc/assets'\nrmvpe_root='/kaggle/working/rvc/assets/rmvpe'\nhubert_path='/kaggle/working/rvc/assets/hubert/hubert_base.pt'\npretrained='/kaggle/working/rvc/assets/pretrained_v2'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load env file\nload_dotenv(f\"{RVC_FOLDER}/rvc.env\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load Model-1\nmiku_vc = VC()\nmiku_vc.get_vc(f\"{RVC_FOLDER}/{RVC_MIKU}/{RVC_MIKU_MODEL_NAME}\")\n    \n# Load Model-2:\nhoshino_vc = VC()\nhoshino_vc.get_vc(f\"{RVC_FOLDER}/{RVC_HOSHINO}/{RVC_HOSHINO_MODEL_NAME}\")\n\n# Load Model-3:\nglados_vc = VC()\nglados_vc.get_vc(f\"{RVC_FOLDER}/{RVC_GLADOS}/{RVC_GLADOS_MODEL_NAME}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rvc_map = dict()\n\nrvc_map[RVC_MIKU] = miku_vc\nrvc_map[RVC_HOSHINO] = hoshino_vc\nrvc_map[RVC_GLADOS] = glados_vc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voices = await edge_tts.list_voices()\nedge_en_voices = list(filter(lambda x: x.startswith(\"en\"), [v[\"ShortName\"] for v in voices]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# HyperDB\nembedding_model = SentenceTransformer(EMBEDDING_MODEL)\nhyper_db_map = dict()\n\n# Fast API\napp = FastAPI()\nrouter_prefix = f\"/{APP_ID}\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DATA TRANSFER OBJECTS","metadata":{}},{"cell_type":"code","source":"class MessageRequest(BaseModel):\n    id: int\n    quotedId: int = None\n    content: str\n    timestamp: int\n    fromRole: str = Field(alias=\"from\")\n    chatId: int\n    assistantId: int\n\nclass ServerResponse(BaseModel):\n    isSuccess: bool\n    statusCode: int\n    errorMessage: str = None\n    errorMessages: dict = None\n    payload: Any = None\n    \nclass AssistantRequest(BaseModel):\n    id: int\n    name: str\n    prompt: str\n    edgeVoice: str\n    edgePitch: int\n    rvcVoice: str","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# UTILITY","metadata":{}},{"cell_type":"code","source":"# Custom exceptions\nclass InvalidToken(Exception):\n    def __init__(self, message, errors=None):\n        self.message = message\n        self.errors = errors\n    def __str__(self):\n        return f\"Message: [{self.message}] Trace: [{self.errors}]\"\n\nclass TokenExpiredException(Exception):\n    def __init__(self, message):\n        self.message = message\n    def __str__(self):\n        return f\"Message: [{self.message}]\"\n\n# Authentication\ndef encrypt(input: str, key: str) -> str:\n    cipher = Cipher(algorithms.AES(key.encode(CHARACTER_ENCODING)), modes.ECB(), backend=default_backend())\n    encryptor = cipher.encryptor()\n    padded_input = pad(input.encode(CHARACTER_ENCODING))\n    encrypted_bytes = encryptor.update(padded_input) + encryptor.finalize()\n    return base64.urlsafe_b64encode(encrypted_bytes).decode(CHARACTER_ENCODING)\n\ndef decrypt(encrypted_input: str, key: str) -> str:\n    cipher = Cipher(algorithms.AES(key.encode(CHARACTER_ENCODING)), modes.ECB(), backend=default_backend())\n    decryptor = cipher.decryptor()\n    decrypted_bytes = decryptor.update(base64.urlsafe_b64decode(encrypted_input)) + decryptor.finalize()\n    return unpad(decrypted_bytes).decode(CHARACTER_ENCODING)\n\ndef pad(data: bytes) -> bytes:\n    padder = padding.PKCS7(128).padder()\n    return padder.update(data) + padder.finalize()\n\ndef unpad(data: bytes) -> bytes:\n    unpadder = padding.PKCS7(128).unpadder()\n    return unpadder.update(data) + unpadder.finalize()\n\ndef generate_token_with_expiration(input: str, expiry_time_days: int, key: str) -> str:\n    current_date = calendar.timegm(time.gmtime())\n    expiration_time = current_date + expiry_time_days * 86400\n    token = f\"{input}{DELIMITER_DATA_DATE}{expiration_time}\"\n    return encrypt(token, key)\n\ndef decrypt_token_with_expiration(token: str, key: str) -> str:\n    try:\n        decrypted_token = decrypt(token, key)\n    except Exception as e:\n        print(f\"[decrypt_token_with_expiration] Invalid token: {e}\")\n        raise InvalidToken(\"Invalid token\", e)\n\n    token_parts = decrypted_token.split(DELIMITER_DATA_DATE)\n    if len(token_parts) == 2:\n        data = token_parts[0]\n        expiration_time = int(token_parts[1])\n        expiration_date = datetime.utcfromtimestamp(expiration_time)\n        current_date = datetime.utcnow()\n        if expiration_date < current_date:\n            logger.warning(\"[decrypt_token_with_expiration] Token has expired\")\n            raise TokenExpiredException(\"Token has expired\")\n        return data\n    else:\n        print(\"[decrypt_token_with_expiration] Invalid token format\")\n        raise InvalidToken(\"Invalid token format\", e)\n        \ndef validate_request(headers: dict):\n    device_id = headers.get(DEVICE_ID_KEY)\n    token = headers.get(AUTHORIZATION_KEY)\n    \n    try:\n        token = decrypt_token_with_expiration(token, AUTH_TOKEN_ENCRYPTION_KEY)\n    except InvalidToken as e:\n        return ServerResponse(isSuccess=False, statusCode=422, errorMessage=e.message)\n    except TokenExpiredException as e:\n        return ServerResponse(isSuccess=False, statusCode=410, errorMessage=e.message)\n        \n    if device_id != token:\n        print(\"[validate_request] Invalid token, DeviceID mismatch\")\n        return ServerResponse(isSuccess=False, statusCode=401, errorMessage=\"Invalid token, DeviceID mismatch\")\n    \n    return device_id\n\n\ndef convert_timestamp_to_date_time(timestamp: int) -> str:\n    epoch_seconds = timestamp / 1000    \n    utc_dt = datetime.utcfromtimestamp(epoch_seconds)\n    kolkata_tz = pytz.timezone('Asia/Kolkata')\n    kolkata_dt = pytz.utc.localize(utc_dt).astimezone(kolkata_tz)\n    date_time = kolkata_dt.strftime(\"%d-%m-%Y %H:%M:%S\")\n    return date_time\n\n# File structure\ndef get_assistant_folder(device_id: str, id: int) -> str:\n    return os.path.join(DEVICES_FOLDER, str(device_id), ASSISTANTS_FOLDER, str(id))\n\ndef create_assistant_folder(device_id: str, assistant_request: AssistantRequest) -> None:\n    id = assistant_request.id\n    prompt = assistant_request.prompt\n    name = assistant_request.name\n    sign = \"\" if assistant_request.edgePitch < 0 else \"+\"\n    edge_rvc_config = {\n        \"edgeVoice\": assistant_request.edgeVoice,\n        \"edgePitch\":f\"{sign}{assistant_request.edgePitch}Hz\",\n        \"rvcVoice\":assistant_request.rvcVoice\n    }\n    \n    folder_path = get_assistant_folder(device_id, id)\n    os.makedirs(folder_path, exist_ok=True)\n    \n    conversation_file = os.path.join(folder_path, CONVERSATION_FILE)\n    with open(conversation_file, 'w', encoding=CHARACTER_ENCODING) as f:\n        pass\n    \n    voice_config_file = os.path.join(folder_path, VOICE_CONFIGURATION_FILE)\n    with open(voice_config_file, 'w', encoding=CHARACTER_ENCODING) as f:\n        f.write(json.dumps(edge_rvc_config, ensure_ascii=False))\n    \n    assistant_name = os.path.join(folder_path, name)\n    with open(assistant_name, 'w', encoding=CHARACTER_ENCODING) as f:\n        pass\n    \n    prompt_file = os.path.join(folder_path, PROMPT_FILE)\n    with open(prompt_file, 'w', encoding=CHARACTER_ENCODING) as f:\n        f.write(prompt)\n        \ndef delete_assistant_folder(device_id: str, id: int) -> None:\n    folder_path = get_assistant_folder(device_id, id)\n    shutil.rmtree(folder_path)\n    \n\n# LLM text generaion\ndef get_hyper_db(device_id, assistant_id):\n    key = f\"{device_id}_{assistant_id}\"\n    if key not in hyper_db_map:\n        conversation_file = os.path.join(get_assistant_folder(device_id, assistant_id), CONVERSATION_FILE) \n        hyper_db_file = os.path.join(get_assistant_folder(device_id, assistant_id), HYPER_DB_FILE)\n        documents = []\n        with open(conversation_file, 'r', encoding=CHARACTER_ENCODING) as f:\n            for line in f:\n                if line == \"\\n\" or line == '':\n                        continue\n                documents.append(line)\n        hyper_db = HyperDB(documents, key=\"content\", embedding_function=embedding_model.encode)\n        hyper_db.save(hyper_db_file)\n        #hyper_db.load(hyper_db_file)\n        hyper_db_map[key] = hyper_db\n    return hyper_db_map[key]\n    \ndef get_instruction_prompt(device_id, assistant_id):\n    instruction_prompt_file = os.path.join(get_assistant_folder(device_id, assistant_id), PROMPT_FILE)\n    instruction_prompt = \"\"\n    with open(instruction_prompt_file, 'r', encoding=CHARACTER_ENCODING) as file:\n        instruction_prompt = file.read()\n    return instruction_prompt\n    \ndef apply_chat_template(input_data):\n    \"\"\"This is for ChatML format\"\"\"\n    if input_data == '' or input_data == '\\n':\n        return input_data\n    output = \"\"\n    json_data = json.loads(input_data)\n    output += f\"<|im_start|>{json_data['role']}\\n\"\n    output += f\"{input_data}<|im_end|>\"\n    return output\n        \ndef apply_chat_template_generate(input_data):\n    \"\"\"This is for ChatML format\"\"\"\n    if input_data == '' or input_data == '\\n':\n        return input_data\n    output = \"\"\n    output += f\"<|im_start|>assistant\\n\"\n    output += f\"{input_data}\"\n    return output\n\ndef apply_chat_template_instruction(input_data):\n    \"\"\"This is for ChatML format\"\"\"\n    if input_data == '' or input_data == '\\n':\n        return input_data\n    output = \"\"\n    output += f\"<|im_start|>system\\n\"\n    output += f\"{input_data}<|im_end|>\"\n    return output\n\ndef generate_text(prompt):\n    input_ids = ExLlamatokenizer.encode(prompt)\n    sys.stdout.flush()\n\n    llm_generator.begin_stream(input_ids, llm_settings)\n\n    generated_tokens = 0\n\n    print(\"\\nOutput: \", end = \"\")\n    generated_text = \"\"\n    while True:\n        chunk, eos, _ = llm_generator.stream()\n        generated_tokens += 1\n        generated_text += chunk\n        print (chunk, end = \"\")\n        sys.stdout.flush()\n        if eos or (len(chunk)>0 and chunk[-1] == '}') or generated_tokens == MAX_NEW_TOKENS: break\n    print()\n    return generated_text\n\ndef remove_brackets(text):\n    square_brackets_pattern = r'\\[.*?\\]'\n    angular_brackets_pattern = r'<.*?>'\n\n    text_without_square_brackets = re.sub(square_brackets_pattern, '', text)\n    cleaned_text = re.sub(angular_brackets_pattern, '', text_without_square_brackets)\n    return cleaned_text\n\n# Edge TTS Generation\nasync def generate_tts(device_id, assistant_id, message_id, text, voice=\"en-US-AriaNeural\", pitch=\"+0Hz\", rate=\"+0%\"):\n    tts_file = os.path.join(get_assistant_folder(device_id, assistant_id), f\"{message_id}_{EDGE_TTS_FILE}\")\n    communicate = edge_tts.Communicate(text, voice=voice, rate=rate, pitch=pitch)\n    await communicate.save(tts_file)\n    return tts_file\n    \n# RVC STS Generation\ndef generate_sts(device_id, assistant_id, message_id, voice=RVC_MIKU):\n    tts_file = os.path.join(get_assistant_folder(device_id, assistant_id), f\"{message_id}_{EDGE_TTS_FILE}\")\n    sts_file = os.path.join(get_assistant_folder(device_id, assistant_id), f\"{message_id}_{RVC_STS_FILE}\")\n    print(tts_file, sts_file)\n    tgt_sr, audio_opt, times, _ = rvc_map[voice].vc_single(1, Path(tts_file))\n    wavfile.write(sts_file, tgt_sr, audio_opt)\n    return sts_file","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# API ENDPOINTS","metadata":{}},{"cell_type":"code","source":"@app.get(f\"{router_prefix}/token\", response_model=ServerResponse)\nasync def get_auth_token(request: Request):\n    auth_key = request.headers.get('auth_key')\n    if not auth_key:\n        print(f\"[ERROR] [get_auth_token] Authentication key is missing\")\n        return ServerResponse(isSuccess=False, statusCode=400, errorMessage=\"Missing authentication key\")\n\n    try:\n        device_id = decrypt(auth_key, AUTH_KEY_DECRYPTION_KEY).split(DELIMITER_DATA_DATE)[0]\n        print(f\"[INFO] [get_auth_token] DeviceID: {device_id}\")\n    except Exception as e:\n        print(f\"[ERROR] [get_auth_token] Invalid key format: {e}\")\n        return ServerResponse(isSuccess=False, statusCode=422, errorMessage=\"Invalid key format\")\n\n    try:\n        token = generate_token_with_expiration(device_id, AUTH_TOKEN_EXPIRY_DAYS, AUTH_TOKEN_ENCRYPTION_KEY)\n        print(f\"[INFO] [get_auth_token] Token: {token}\")\n        return ServerResponse(isSuccess=True, statusCode=200, payload=token)\n    except Exception as e:\n        print(f\"[ERROR] [get_auth_token] Error generating token: {e}\")\n        return ServerResponse(isSuccess=False, statusCode=500, errorMessage=\"[get_auth_token] Error generating token\")\n\n@app.get(f\"{router_prefix}/status\", response_model=ServerResponse)\nasync def get_status(request: Request):\n    return ServerResponse(isSuccess=True, statusCode=200, payload=\"[get_status] ARA Server is up and running\")\n    \n    \n@app.post(f\"{router_prefix}/assistant/create\", response_model=ServerResponse)\nasync def create_assistant(request: Request, assistant_request: AssistantRequest):\n    validated_data = validate_request(request.headers)\n    if isinstance(validated_data, ServerResponse):\n        return validated_data\n    device_id = validated_data\n        \n    try:\n        create_assistant_folder(device_id, assistant_request)\n        return ServerResponse(isSuccess=True, statusCode=200, payload=\"Assistant created successfully\")\n    except Exception as e:\n        print(f\"[ERROR] [create_assistant] Error creating assistant: {e}\")\n        return ServerResponse(isSuccess=False, statusCode=500, errorMessage=\"Error creating assistant\")\n    \n    \n@app.delete(f\"{router_prefix}/assistant/delete/{{assistantId}}\", response_model=ServerResponse)\nasync def delete_assistant(request: Request, assistantId):\n    validated_data = validate_request(request.headers)\n    if isinstance(validated_data, ServerResponse):\n        return validated_data\n    device_id = validated_data\n    \n    try:\n        delete_assistant_folder(device_id, assistantId)\n        return ServerResponse(isSuccess=True, statusCode=200, payload=\"Assistant deleted successfully\")\n    except Exception as e:\n        print(f\"[ERROR] [delete_assistant] Error deleting assistant: {e}\")\n        return ServerResponse(isSuccess=False, statusCode=500, errorMessage=\"Error deleting assistant\")\n    \n    \n@app.delete(f\"{router_prefix}/message/delete/{{assistantId}}/{{messageId}}\", response_model=ServerResponse)\nasync def delete_message(request: Request, assistantId, messageId):\n    validated_data = validate_request(request.headers)\n    if isinstance(validated_data, ServerResponse):\n        return validated_data\n    device_id = validated_data\n    \n    try:\n        deleted = False\n        conversation_file = os.path.join(get_assistant_folder(device_id, assistantId), CONVERSATION_FILE)        \n        temp_file = os.path.join(get_assistant_folder(device_id, assistantId), TEMP_FILE)     \n        with open(conversation_file, 'r', encoding=CHARACTER_ENCODING) as file:\n            with open(temp_file, 'w', encoding=CHARACTER_ENCODING) as output:\n                for line in file:\n                    if line == \"\\n\" or line == '':\n                        continue\n                    try:\n                        message = json.loads(line)\n                        if int(message.get(\"id\")) != int(messageId):\n                            output.write(line)\n                        else:\n                            deleted = True\n                            key = f\"{device_id}_{assistantId}\"\n                            hyper_db_map.pop(key, -1)\n                    except json.JSONDecodeError:\n                        print(f\"[WARN] Error decoding line: {line}\")\n                        output.write(line)\n        \n        os.replace(temp_file, conversation_file)\n        \n        if deleted:\n            return ServerResponse(isSuccess=True, statusCode=200, payload=\"Message deleted successfully\")\n        return ServerResponse(isSuccess=False, statusCode=404, payload=\"Message not found\")\n    except Exception as e:\n        print(f\"[ERROR] [delete_message] Error deleting message: {e}\")\n        return ServerResponse(isSuccess=False, statusCode=500, errorMessage=\"Error deleting message\")\n    \n@app.put(f\"{router_prefix}/message/edit\", response_model=ServerResponse)\nasync def edit_message(request: Request, message_request: MessageRequest):\n    validated_data = validate_request(request.headers)\n    if isinstance(validated_data, ServerResponse):\n        return validated_data\n    device_id = validated_data\n    \n    try:\n        edited = False\n        conversation_file = os.path.join(get_assistant_folder(device_id, message_request.assistantId), CONVERSATION_FILE)        \n        temp_file = os.path.join(get_assistant_folder(device_id, message_request.assistantId), TEMP_FILE)     \n        with open(conversation_file, 'r', encoding=CHARACTER_ENCODING) as file:\n            with open(temp_file, 'w', encoding=CHARACTER_ENCODING) as output:\n                for line in file:\n                    if line == \"\\n\" or line == '':\n                        continue\n                    try:\n                        message = json.loads(line)\n                        if int(message.get(\"id\")) != int(message_request.id):\n                            output.write(line)\n                        else:\n                            edited = True\n                            message[\"content\"] = message_request.content\n                            output.write(json.dumps(message, ensure_ascii=False) + \"\\n\")\n                            key = f\"{device_id}_{message_request.assistantId}\"\n                            hyper_db_map.pop(key, -1)\n                    except json.JSONDecodeError:\n                        print(f\"[WARN] Error decoding line: {line}\")\n                        output.write(line)\n        \n        os.replace(temp_file, conversation_file)\n        \n        if edited:\n            return ServerResponse(isSuccess=True, statusCode=200, payload=\"Message edited successfully\")\n        return ServerResponse(isSuccess=False, statusCode=404, payload=\"Message not found\")\n    except Exception as e:\n        print(f\"[ERROR] [edit_message] Error editing message: {e}\")\n        return ServerResponse(isSuccess=False, statusCode=500, errorMessage=\"Error editing message\")\n    \n    \n@app.post(f\"{router_prefix}/message/upload\", response_model=ServerResponse)\nasync def upload_message(request: Request, message_request: MessageRequest):\n    validated_data = validate_request(request.headers)\n    if isinstance(validated_data, ServerResponse):\n        return validated_data\n    device_id = validated_data\n\n    try:\n        hyper_db = get_hyper_db(device_id, message_request.assistantId)\n\n        message_data = {\n            \"id\": message_request.id,\n            \"role\": message_request.fromRole.lower(),\n            \"time\": convert_timestamp_to_date_time(message_request.timestamp),\n            \"content\": message_request.content,\n        }\n        if message_request.quotedId is not None:\n            message_data[\"replyto\"] = message_request.quotedId\n        \n        print(f\"[INFO] [upload_message] YOU: {str(message_data)}\")\n        conversation_file = os.path.join(get_assistant_folder(device_id, message_request.assistantId), CONVERSATION_FILE)\n        with open(conversation_file, 'a', encoding=CHARACTER_ENCODING) as f:\n            f.write(\"\\n\" + json.dumps(message_data, ensure_ascii=False))\n        hyper_db.add_document(json.dumps(message_data, ensure_ascii=False))\n            \n        return ServerResponse(isSuccess=True, statusCode=201, payload=\"Message uploaded successfully\")\n    except Exception as e:\n        print(f\"[ERROR] [upload_message] Error uploading message: {e}\")\n        return ServerResponse(isSuccess=False, statusCode=500, errorMessage=\"Error uploading message\")\n    \n    \n@app.post(f\"{router_prefix}/assistant/response\", response_model=ServerResponse)\nasync def assistant_response(request: Request, message_request: MessageRequest):\n    validated_data = validate_request(request.headers)\n    if isinstance(validated_data, ServerResponse):\n        return validated_data\n    device_id = validated_data\n    \n    try:\n        hyper_db = get_hyper_db(device_id, message_request.assistantId)\n        conversation_file = os.path.join(get_assistant_folder(device_id, message_request.assistantId), CONVERSATION_FILE)\n        lines = []\n        with open(conversation_file, 'r', encoding=CHARACTER_ENCODING) as f:\n            lines = f.read().splitlines()\n            \n        last_context = lines[-LAST_CONTEXT:] if len(lines) > 0 else []\n        \n        results = hyper_db.query(json.loads(last_context[-1])[\"content\"], top_k=LONG_TERM_CONTEXT) if len(lines) > 0 else []\n        related_context = [doc.rstrip('\\n') for doc, _ in results]\n        \n        related_context = [line for line in related_context if line not in last_context]\n                \n        timestamp = time.time() * 1000\n        date_time = convert_timestamp_to_date_time(timestamp)\n        message_data = {\n            \"id\": message_request.id,\n            \"role\": message_request.fromRole.lower(),\n            \"time\": date_time,\n            \"content\": \"\"\n        }\n        new_message = [json.dumps(message_data, ensure_ascii=False)[:-2]]  # Leave out the \"}\n        \n        instruction_prompt = get_instruction_prompt(device_id, message_request.assistantId)\n        combined_inputs = related_context + last_context + new_message\n        \n        print(f\"[INFO] [assistant_response] Related context: {related_context}\")\n        print(f\"[INFO] [assistant_response] Last context: {last_context}\")\n        print(f\"[INFO] [assistant_response] New context: {new_message}\")\n        \n        if APPLY_CHAT_TEMPLATE:\n            combined_inputs = [apply_chat_template(input_data) for input_data in (related_context + last_context)] \\\n                            + [apply_chat_template_generate(new_message[0])]\n            instruction_prompt = apply_chat_template_instruction(instruction_prompt)\n            \n        prompt = instruction_prompt + '\\n' + '\\n'.join(combined_inputs)\n        print(f\"[INFO] [assistant_response] Final prompt:\\n{prompt}\")\n        \n        message_generated = generate_text(prompt)\n        print(f\"[INFO] [assistant_response] Generated: {message_generated}\")\n        \n        try:\n            voice_config_file = os.path.join(get_assistant_folder(device_id, message_request.assistantId), VOICE_CONFIGURATION_FILE)\n            voice_config = \"{}\"\n            with open(voice_config_file, 'r', encoding=CHARACTER_ENCODING) as f:\n                voice_config = f.readline()\n            edge_rvc_config = json.loads(voice_config)\n            \n            cleaned_generation = remove_brackets(message_generated).split('\"')[0].replace(\"\\n\", \" \").replace(\"/n\", \" \")\n            print(f\"[INFO] [assistant_response] Cleaned: {cleaned_generation}\")\n            audio_generated = await generate_tts(device_id, message_request.assistantId, message_request.id,\n                 text=cleaned_generation, voice=edge_rvc_config[\"edgeVoice\"], pitch=edge_rvc_config[\"edgePitch\"])\n\n            print(f\"[INFO] [assistant_response] Edge TTS Completed\")\n            if edge_rvc_config.get(\"rvcVoice\") != None and edge_rvc_config.get(\"rvcVoice\") != \"\":\n                audio_generated = generate_sts(device_id, message_request.assistantId,\n                                               message_request.id, edge_rvc_config[\"rvcVoice\"])\n            print(f\"[INFO] [assistant_response] RVC STS Completed\")\n            \n        except Exception as e:\n            print(f\"[ERROR] [assistant_response] TTS Error : {e}\")\n        \n        message_generated = new_message[0] + message_generated + \"}\"\n        message_generated_json = {}\n        try:\n            message_generated_json = json.loads(message_generated)\n        except Exception as e:\n            print(f\"[ERROR] [assistant_response] JSON Error : {e}\")\n            return ServerResponse(isSuccess=False, statusCode=500, payload=message_generated,\n                                  errorMessage=\"Generated response is not in JSON\")\n        \n        with open(conversation_file, 'a', encoding=CHARACTER_ENCODING) as f:\n            f.write(\"\\n\" + message_generated)\n        hyper_db.add_document(message_generated)\n\n        message_response = {\n            \"id\": message_request.id,\n            \"from\": message_request.fromRole,\n            \"content\": message_generated_json[\"content\"],\n            \"quotedId\": message_generated_json.get(\"replyto\"),\n            \"timestamp\": round(timestamp)\n        }\n        return ServerResponse(isSuccess=True, statusCode=200, payload=message_response)\n    except Exception as e:\n        print(f\"[ERROR] [assistant_response] Error generating assistant response: {e}\")\n        return ServerResponse(isSuccess=False, statusCode=500, errorMessage=\"Error generating assistant response\")\n    \n\n@app.get(f\"{router_prefix}/assistant/voice-models\", response_model=ServerResponse)\nasync def assistant_voice_models(request: Request):\n    validated_data = validate_request(request.headers)\n    if isinstance(validated_data, ServerResponse):\n        return validated_data\n    device_id = validated_data\n    \n    payload = {\n        \"edgeVoiceModels\": edge_en_voices,\n        \"rvcVoiceModels\": list(rvc_map.keys())\n    }\n    return ServerResponse(isSuccess=True, statusCode=200, payload=payload)\n    \n    \n@app.get(f\"{router_prefix}/assistant/response_audio/{{assistantId}}/{{messageId}}\")\nasync def assistant_response_audio(request: Request, assistantId, messageId):\n    validated_data = validate_request(request.headers)\n    if isinstance(validated_data, ServerResponse):\n        return validated_data\n    device_id = validated_data\n    \n    tts_file = os.path.join(get_assistant_folder(device_id, assistantId), f\"{messageId}_{EDGE_TTS_FILE}\")\n    sts_file = os.path.join(get_assistant_folder(device_id, assistantId), f\"{messageId}_{RVC_STS_FILE}\")\n    \n    audio_file_path = sts_file if os.path.isfile(sts_file) else tts_file\n    return FileResponse(audio_file_path, media_type=\"audio/wav\", filename=f\"{messageId}.wav\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# THREADS","metadata":{}},{"cell_type":"code","source":"stop_event = threading.Event()\n\ndef fastAPIThread(stop_event):\n    config = uvicorn.Config(app, host=\"0.0.0.0\", port=5003)\n    server = uvicorn.Server(config)\n\n    loop = asyncio.new_event_loop()\n    asyncio.set_event_loop(loop)\n\n    server_task = loop.create_task(server.serve())\n\n    try:\n        while not stop_event.is_set():\n            loop.run_until_complete(asyncio.sleep(1))\n    except KeyboardInterrupt:\n        pass\n    finally:\n        server.should_exit = True\n        loop.run_until_complete(server_task)\n        loop.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ngrok_process = None\n\ndef run_ngrok():\n    global ngrok_process\n    command = [\"ngrok\", \"http\", f\"--domain={NGROK_STATIC_DOMAIN}\", \"5003\"]\n    ngrok_process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n    for line in ngrok_process.stdout:\n        print(line.strip())\n    \ndef stop_ngrok():\n    global ngrok_process\n    if ngrok_process:\n        ngrok_process.terminate()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ngrok config add-authtoken {NGROK_AUTHTOKEN}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EXECUTE","metadata":{}},{"cell_type":"code","source":"server_thread = threading.Thread(target=fastAPIThread, args=(stop_event,), daemon=True)\nserver_thread.start()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ngrok_thread = threading.Thread(target=run_ngrok, daemon=True)\nngrok_thread.start()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Infinite loop to prevent idle timeout\nprint('--LOGS--')\ntry:\n    while True:\n        # Sleep for 5 minutes\n        time.sleep(300)\nexcept KeyboardInterrupt:\n    print(\"Interrupted! Stopping the loop.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CLEANUP","metadata":{}},{"cell_type":"code","source":"stop_event.set()\nserver_thread.join()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop_ngrok()\nngrok_thread.join()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}